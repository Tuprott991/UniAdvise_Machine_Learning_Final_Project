import os
import json
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
import re

# Load API key
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# Kh·ªüi t·∫°o LLM
llm = ChatOpenAI(temperature=0.3, model="gpt-4o-mini")  # Ho·∫∑c gpt-3.5-turbo

# Prompt template ƒë·ªÉ chuy·ªÉn markdown th√†nh Q&A
qa_prompt = PromptTemplate.from_template("""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI gi√∫p t·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán LLM. H√£y ƒë·ªçc ƒëo·∫°n th√¥ng tin sau v·ªÅ m·ªôt tr∆∞·ªùng ƒë·∫°i h·ªçc v√† tr√≠ch xu·∫•t ra c√°c c·∫∑p "C√¢u h·ªèi - Tr·∫£ l·ªùi" ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh ng√¥n ng·ªØ.

Y√™u c·∫ßu:
- M·ªói c·∫∑p d∆∞·ªõi d·∫°ng: {{
    "messages": [
        {{"role": "user", "content": "C√¢u h·ªèi?"}},
        {{"role": "assistant", "content": "C√¢u tr·∫£ l·ªùi"}}
    ]
}}
- Ph·∫£i ƒë·∫£m b·∫£o c√°c c·∫∑p Q&A ph·∫£i ch√≠nh x√°c v√† bao g·ªìm ƒë·∫ßy ƒë·ªß th√¥ng tin c√≥ trong ƒëo·∫°n vƒÉn b·∫£n v√† kh√¥ng ƒë∆∞·ª£c th√™m b·∫•t k·ª≥ th√¥ng tin n√†o kh√°c.
- ƒê·∫£m b·∫£o c√°c c·∫∑p Q&A kh√¥ng b·ªã tr√πng l·∫∑p.
- ƒê·∫£m b·∫£o n·ªôi dung tr·∫£ v·ªÅ ƒë√∫ng format JSON ƒë·ªÉ c√≥ th·ªÉ json.loads() ƒë∆∞·ª£c.
- Kh√¥ng th√™m b·∫•t k·ª≥ k√Ω t·ª± ho·∫∑c n·ªôi dung n√†o ngo√†i JSON.
- N·ªôi dung:
```markdown
{md} """)

def extract_json(response):
    # T√¨m ph·∫ßn n·∫±m trong ```json ... ```
    match = re.search(r"```json\s*(\[.*?\])\s*```", response, re.DOTALL)
    if match:
        json_str = match.group(1)
    else:
        # N·∫øu kh√¥ng c√≥ block ```json```, th·ª≠ l·∫•y ph·∫ßn list JSON ƒë·∫ßu ti√™n
        match = re.search(r"(\[\s*{.*?}\s*\])", response, re.DOTALL)
        if match:
            json_str = match.group(1)
        else:
            return []

    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        print(f"‚ö†Ô∏è JSON decode error: {e}")
        return []

def md_to_qa(md_content: str) -> list:
    prompt = qa_prompt.format(md=md_content)
    response = llm.predict(prompt)
    try:
        data = extract_json(response)
        return data
    except json.JSONDecodeError as e:
        print(f"‚ö†Ô∏è JSON decode error: {e}")
        return []

    
def generate_finetune_dataset_from_md(md_path, output_path):
    with open(md_path, "r", encoding="utf-8") as f:
        md_content = f.read()

    print(f"\nüß† ƒêang x·ª≠ l√Ω file: {md_path.split('/')[-1]} ...")

    # G·ªçi LLM tr·ª±c ti·∫øp
    qa_pairs = md_to_qa(md_content)

    if not isinstance(qa_pairs, list):
        print("‚ö†Ô∏è K·∫øt qu·∫£ kh√¥ng ph·∫£i danh s√°ch!")
        return

    with open(output_path, "w", encoding="utf-8") as f:
        for item in qa_pairs:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    print(f"\n‚úÖ Dataset ƒë√£ l∆∞u t·∫°i: {output_path}")

if __name__ == "__main__":
    md_dir = "crawl_results"
    output_dir = "dataset"
    os.makedirs(output_dir, exist_ok=True)

    for filename in os.listdir(md_dir):
        if filename.endswith(".md"):
            md_path = os.path.join(md_dir, filename)
            output_path = os.path.join(output_dir, f"{filename}.jsonl")
            generate_finetune_dataset_from_md(md_path, output_path)
